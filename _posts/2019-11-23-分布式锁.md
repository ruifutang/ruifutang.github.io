---
layout:     post  
title:      热点 key 穿透缓存了怎么办     
subtitle:   分布式锁怎么锁    
date:       2019-11-23    
author:     唐瑞甫  
header-img: img/post-bg-coffee.jpeg  
catalog: true  
tags:  
    - redis  
    - zookeeper  

---  

上篇文章最后留了一个问题，也就是热点 key 所导致的瞬时流量泛洪的问题。要想解决这个问题，思路就是要避免热点 key 失效。这篇文章专门来聊一聊，如何避免热点 key 所导致的缓存击穿的问题。  
  
### 缓存不过期  
  
这是最容易想到的方案，实现起来并没有想象中的那般容易。由于缓存不过期，所以很容易出现「内存占满」的情况，这时如果没有指定内存淘汰策略，则会出现缓存无法写入的情况，导致异常发生。比如 redis 默认的[内存淘汰策略](https://redis.io/topics/lru-cache)在内存占满的情况下写入会直接报错。  
  
通常有两种思路来实现缓存不过期。  
  
第一种就是直接将所有 key 设置为不过期，这种方案比较适用于缓存诸如全局配置这种数据。如果是那种数据量非常大又需要频繁写入的类型，则意味着在内存占满之后需要频繁地删除数据并写入数据，会影响性能。  
  
第二种就需要「实时监控」来发现出热点 key，然后及时地将这些 key 值设置为不过期，这样既提高内存的使用效率，又不会影响写入性能。唯一需要解决的问题就是，如何发现热点 key。  
  
#### 发现热点key   
  
![](https://redislabs.com/wp-content/uploads/2018/11/diagram-redis-flash-memory-architecture-2018.png?_t=1541094584)  
  
对于如何发现热点 key 的问题，这里以 redis 为例，提供一些思路以供参考。  

1. 事先进行预判
  
	比如现在要做一个秒杀活动，那么这些商品对应的 key 就会成为热点 key。这个方案的缺点也很明显，就是并非所有业务都能进行预判，只适用特定的场景。
  
2. 在客户端进行收集
  
	在调用方的代码中对 redis 操作进行统计，可以得到针对每个 key 的访问次数。数据统计的方式有很多种，可以在内存中直接累加，也可以上报数据给外部依赖的系统。该方案的缺点就是对调用方代码造成入侵。
  
3. 在 Proxy 层做收集
 
	如果系统架构中有专门的中间层做代理去操作 redis ，那么就可以在 proxy 里面去做统计。这个方案跟 1 类似，缺点就是只适合有 proxy 的系统架构。  
  
4. 用 redis 自带命令

	4.1 monitor 命令。但是该命令在高并发的条件下，有内存增暴增的隐患，还会降低 redis 的性能。

	4.2 hotkeys 参数。但是该参数在执行的时候，如果key比较多，执行起来比较慢。
  
孰优孰劣，只有放到实际的场景里比较，才会有意义。  
  
对于解决热点 key 击穿这个问题，还有一种实际中更常用的解决方案 -- 「分布式锁」。  
  
### 分布式锁  
  
![](https://cdn.yangbingdong.com/img/distribute-lock/distribute-lock-banner.png)

首先，什么是锁？  
  
简单说，锁是实现「**多线程**」同时访问同一资源，保证同一时刻只有一个线程可访问共享资源所做的一种标记。  
  
而「分布式锁」，则是指「**分布式环境**」下，系统部署在多个机器中，实现分布式「**多进程**」互斥的一种锁。 

在热点 key 的场景中，当 key 失效时，通过引入分布式锁可以保证 DB 同一时间只能被一个进程访问，这样也能解决缓存击穿的问题。  
  
有三种常见的方法来实现分布式锁：  
  
- 基于 DB 实现分布式锁  
- 基于 Redis 实现分布式锁
- 基于 ZooKeeper 实现分布式锁  
  
#### 基于 DB 实现  
  
如果多个请求同时提交，DB 会保证「**只有一个操作可以成功**」。  
  
可以利用 DB 的这一特性来实现分布式锁。创建一张锁表，当我们要锁住某个资源时，就在该表中增加一条记录，想要释放锁的时候就删除这条记录。  
  
```sql
CREATE TABLE `t_distributed_lock` (
  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键',
  `key` varchar(64) NOT NULL DEFAULT '' COMMENT '缓存 key 值',
  `modify_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uidx_key` (`key`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='分布式锁表';
```  
可以这样进行加锁：  
  
```
insert into t_distributed_lock set key = 'tokyo_hot';  
```  
  
可以这样进行解锁：  
  
```
delete from t_distributed_lock key = 'tokyo_hot' limit 1;  
```  
  
这个方案会有以下几点需要注意：  
  
1. 单节点问题。由于强依赖 DB 的可用性，一旦 DB 挂掉，会导致业务系统不可用。  
    
	可以考虑主备/主从架构，一旦主机挂掉的话就将流量切换到备机上，这就需要保证备机的 binlog 与主机是同步的，不会落后太多，这样切换的时候不会造成太大的延迟。  
	
2. 宕机死锁问题。DB 锁没有失效时间，未获得锁的进程只能一直等待已获得锁的进程主动释放锁。一旦已获得锁的进程挂掉或者解锁操作失败，会导致锁记录一直存在数据库中，其他进程无法获得锁。
  
  可以启用一个后台线程做轮训，每隔一定时间把数据库中的超时数据清理一遍，例如当前时间减去 modify_time 超过 1 分钟的记录直接删除。  
   
当然也可以利用数据库本身的排它锁来实现分布式锁。 
  
需要事先在 DB 中事先插入一条记录。
  
``` 
insert into t_distributed_lock set key = 'tokyo_hot';  
```  
  
加锁就可以这样  
  
```  
begin;  
  
select id from t_distributed_lock where key = 'tokyo_hot' for update;  
```

解锁就可以这样  
  
```
commit;  
```

使用这种方式，宕机之后 DB 会自己把锁释放掉。  
  
不过这个方案有几个点需要特别注意
  
1. Mysql 会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。这样将极大影响到整个业务的吞吐量。  
  
  这里可以使用 「force index」来强制使用索引来避免全表扫描。  
    
  ```
  select id from t_distributed_lock force index(uidx_key) where key = 'tokyo_hot' for update;  
  ```
  
2. for update 使用排他锁来进行加锁操作，如果长时间不提交，就会占用 DB 连接。一旦类似的连接变多了，就可能把连接池撑爆。  
  
  设置 Transaction 超时时间，避免大量连接占用连接池。
    
  ```
  set innodb_lock_wait_timeout = 10;  
  ```  
  注意，这里需要打开 innodb_rollback_on_timeout，而且需要在 mysqld 服务启动的时候指定  
  
  ```  
  ./mysqld_safe --user=mysql --innodb_use_native_aio=0 --datadir=/data/mysqlData --innodb_rollback_on_timeout=ON  
  ```
  否则超时只会回滚 sql 而不是 transaction。  
  
  > InnoDB rolls back only the last statement on a transaction timeout by default. If innodb_rollback_on_timeout is specified, a transaction timeout causes InnoDB to abort and roll back the entire transaction (the same behavior as before MySQL 5.0.13). This variable was added in MySQL 5.0.32.
  
  
  然后设置竞争锁的过程中为非阻塞，抢不到锁不会等待直接返回。  
    
  ```  
  select id from t_distributed_lock where key = 'tokyo_hot' for update NOWAIT;   
  ```  
  
总得来说，因为 DB 需要落磁盘，频繁读取 DB 会增大 IO，因此这种分布式锁适用于并发量低，对性能要求低的场景。



#### 基于 Redis 实现

可以使用 [setnx(key, value)](https://redis.io/commands/setnx) 函数来实现分布式锁。当持有锁的时间超过设置的 timeout 时，锁会被系统释放。  
  
```
SET resource_name random_value NX PX timeout  
```
  
random_value 是由 client 生成的一个随机字符串，需要保证在所有 client 的请求中是全局唯一的。  
  
当需要释放锁的时候，需要先调用 GET 通过 random_value 来判断是否是自己上的锁，而不能直接调用 DEL 来释放。所以这里需要通过 Redis Lua 脚本来释放锁。  
  
```
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end  
```  
  
其中 ARGV[1] 设置为 random_value， KEYS[1] 设置为 resource_name。  
  
由于 Redis Lua 脚本能够保证原子性，所以不用担心并发所导致的数据不一致的问题。 
  
> Redis uses the same Lua interpreter to run all the commands. Also Redis guarantees that a script is executed in an atomic way: no other script or Redis command will be executed while a script is being executed. This semantic is similar to the one of MULTI / EXEC.  

不过目前 Redis 并不推荐这个方案来实现分布式锁，如果此时 Redis 服务出现宕机的情况会导致分布式锁不可用，所以需要一个分布式的高可用服务。 
  
> This pattern is discouraged in favor of the Redlock algorithm which is only a bit more complex to implement, but offers better guarantees and is fault tolerant.  
  
Redis 专门实现了基于多个完全独立的 Redis 节点的分布式算法 --  [Redlock](https://redis.io/topics/distlock)，并且提供了各个语言的版本直接可以使用，比如 [JAVA 版本](https://github.com/redisson/redisson) 和 [ C++ 版本](https://github.com/jacket-code/redlock-cpp) 等。  
  
有关 Redlock 的方案这里就不展开了，可以参考下这篇 -- [基于Redis的分布式锁到底安全吗](http://zhangtielei.com/posts/blog-redlock-reasoning.html)
    
总的来说，相比于 DB 实现的方案，Redis 性能更好。数据被存放在内存而不是磁盘，避免了频繁的 IO 操作。而且 Redis 可以支持集群部署，解决了单点故障的问题。再加上 Redis 官方开源了各语言版本的实现方案，实际中如果需要用到分布式锁的场景，Redis 是个不错的选择。  
  
#### 基于 Zookeeper 实现  
  
> ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services.
  
ZooKeeper 中的节点 znode 具有以下几点性质：  
  
1. 有序节点：可以创建子节点时并且指明有序，那么 ZooKeeper 在生成子节点时会根据当前的子节点数量自动添加整数序号。
  
2. 临时节点：可以建立一个临时节点，在会话结束或者会话「超时」后，zookeeper会自动删除该节点。  
  
3. 事件监听：在读取数据时，我们可以同时对节点设置事件监听，当节点数据或结构变化时，ZooKeeper 会通知客户端。当前有如下四种事件会进行通知：1）节点创建；2）节点删除；3）节点数据修改；4）子节点变更。  
  
可以基于「**临时有序节点**」可以实现分布式锁。  
  
1. 在根节点 /lock 下创建临时有序的子节点，第一个 client 对应的子节点为/lock/lock-0000000000，第二个为/lock/lock-0000000001，以此类推。  
  
2. client 获取 /lock 下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则代表获得锁，否则监听根节点下所有子节点变更消息，获得子节点变更通知后重复此步骤直至获得锁；
  
3. 删除子节点则代表释放锁。  
  
这里有个问题，比如 a 对应子节点为编号为 0(方便演示简化了编号)，b对应子节点编号为 1，b 获取子节点列表时发现自己不是序号最小的，但是在设置监听器前 a 删除了编号为 0 的子节点，那这样 b 设置的监听器会因为接受不到变更通知而一直阻塞在等待状态中。  
  
不过 zookeeper 提供的 API 中设置监听器的操作与读操作是「**原子**」执行的，所以这个问题是不存在的。  
  
如果获得锁的 client 释放锁时，剩下所有的 client 都会被唤醒，就会出现「**herd effect(羊群效应)**」  
  
> The herd effect refers to releasing a "herd" when in fact only a single or a small number of machines can proceed.
  
这是 zookeeper server 端会在这一瞬间收到大量通知，可能会导致网络的阻塞，引起一系列的问题。
  
所以每次释放锁时只唤醒剩下节点中的编号最小的节点对应的 client，在设置事件监听时，每个 client 应该对刚好在它之前的子节点设置事件监听，编号为 2 的 client 监听编号为 1 的子节点删除消息，编号为 1 的监听序号为 0 的子节点删除消息。  
  
于是可以对上述流程中的第 2 步进行优化。  
  
client 获取 /lock 下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则代表获得锁，否则**监听刚好在自己之前一位的子节点删除消息**，获得子节点变更通知后重复此步骤直至获得锁。  
  
利用 zookeeper 实现分布式锁，优点就是可靠性高，扩展性好，不会有单点故障。缺点就是需要专门引入 zookeeper 组件，实现成本较高。不过这里可以考虑 [Curator](http://curator.apache.org/index.html)  
  
> Curator is a Java/JVM client library for Apache ZooKeeper, a distributed coordination service. It includes a highlevel API framework and utilities to make using Apache ZooKeeper much easier and more reliable.
  
基于 ZooKeeper 的分布式锁和基于 Redis 的分布式锁有两个区别：  
    
1. ZooKeeper 不用设置 timeout，client 可以持有锁任意长的时间，这可以确保它做完所有需要的资源访问操作之后再释放锁。这避免了基于 Redis 的锁对于超时时间设置的问题，太短太长都不合适。由于 ZooKeeper 依靠Session（心跳）来维持锁的持有状态的，所以不用担心节点宕机导致一直占有锁的问题。  
2. 基于 ZooKeeper 的锁支持在获取锁失败之后等待锁释放的事件通知，而基于 Redis 的锁必须要 client 主要去请求来判断锁是否已经被释放了。  
   
### 方案对比  
  
通常来讲，缓存不过期的方案适用于全局配置，静态数据这类的场景，而在大规模的场景中，分布式锁可能会更实用。  
  
用 DB 实现分布式锁的方案适用于并发量低且对性能要求不高的场景， Redis 的方案适用于高并发并且对性能要求高的场景，而 zookeeper 除了对性能要求极高的场景不适用之外其他场景都能适用。  
  
但是不要忘了，具体场景具体分析。  
  
 
--「天道酬勤 地道酬善」









 
---
  By 唐瑞甫  
  2019-11-23

