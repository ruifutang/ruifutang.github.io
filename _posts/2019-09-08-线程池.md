---
layout:     post  
title:      听说一行代码就能实现线程池了？  
subtitle:   还有这种操作   
date:       2019-09-08  
author:     唐瑞甫  
header-img: img/post-bg-coffee.jpeg  
catalog: true  
tags:   
    - c++  

---  

一行代码真的能实现线程池吗？  
  
当然可以啊，不信我写给你看  
  
```
	std::vector<std::thread> TreadPool;
```

是不是只要一行。  
  
![功夫](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1567964420009&di=d0afff3616df126c5285ec68214cf5a7&imgtype=0&src=http%3A%2F%2Fqiniuimg.qingmang.mobi%2Fimage%2Forion%2F26c6df78bdd4495ec66ad031fb1af2b6_1600_899.jpeg)  
  
玩笑归玩笑，实现一个线程池其实并不复杂，但是想写好其实并不容易。  
  
C++11 发布了大量新的特性，实现一个简易版的线程池其实已经不需要依赖外部的库了，话不多说，直接上手。  
  
```c++
using Func = std::function<void(void)>;
using Lock = std::unique_lock<std::mutex>;

class ThreadPool {
public:
    ThreadPool(size_t threads = std::thread::hardware_concurrency());
    
    template<class F, class... Args>
    auto enqueue(F&& f, Args&&... args) -> std::future<typename std::result_of<F(Args...)>::type>;
    ~ThreadPool();
    
private:
    using ThreadVec = std::vector<std::thread>;
    ThreadVec m_threads;
    std::queue< Func > m_tasks;
    
    std::mutex m_mtx;
    std::condition_variable m_cv;
    bool m_ready;
};
 
ThreadPool::ThreadPool(size_t threads)
    :   m_ready(true)
{
    for(size_t i=0; i<threads; ++i)
	{
        m_threads.emplace_back(
            [this]
            {
                for(;;)
                {
                    Func task;
                    Lock lock(this->m_mtx);
                    this->m_cv.wait(lock,
                        [this]{ return !this->m_ready || !this->m_tasks.empty(); });
						
                    if(!this->m_ready && this——>m_tasks.empty())
                    {
                    	return;
                    }
                    task = std::move(this->m_tasks.front());
                    this->m_tasks.pop();

                    task();
                }
            }
        );
	}
}

template<class F, class... Args>
auto ThreadPool::enqueue(F&& f, Args&&... args) 
    -> std::future<typename std::result_of<F(Args...)>::type>
{
    using return_type = typename std::result_of<F(Args...)>::type;

    auto task = std::make_shared< std::packaged_task<return_type()> >(
            std::bind(std::forward<F>(f), std::forward<Args>(args)...)
        );
        
    std::future<return_type> res = task->get_future();
	
	{
		Lock lock(m_mtx);
	
		if(!m_ready)
		{
			throw std::runtime_error("ThreadPool not ready");
		}
	
		m_tasks.emplace(
			[task]
			{
				(*task)(); 
			}
		);
	}  
	
    // already unlock        
    m_cv.notify_one();
    return res;
}

inline ThreadPool::~ThreadPool()
{
	{
		Lock lock(m_mtx);
		m_ready = false;
	}  
	
	// already unlock    
    m_cv.notify_all();
    for(auto &thread: m_threads)
	{
        thread.join();
	}
}
```
有如下几点需要说明：  
  
1.  代码中有两处我备注了 already unlock 。这里其实是一个「Optimization」。在 Notify 时如果持有同一个 mutex 上的锁，则线程在被唤醒之后又会立马阻塞，等待 Notify 线程释放锁。  
2.  enqueue 中的 tasks 之所以要被 std::make_shared 是因为 packaged_task 是不允许被 copy 的(copy constructor was deleted)，而 task 又需要被拷贝到 std::function\<void(void)> 中然后加入到队列里面。  
3.  通过 ready 变量可以控制 TreadPool 的开关操作。  
    
    
不难发现，有两处地方存在『可优化』的空间。  
『其一』，由于 condition_variable 与 mutex 是成对出现的，所以可以做下封装。  
『其二』，代码中采用的最基本的 queue 来实现 pool，所以需要额外地做一些同步的操作，所以可以用 「blocking queue」来代替 queue，这样可以达到『有则消费，无则等待』的效果。  
  
如果你还不清楚 『为什么 condition_variable 需要 mutex 搭配使用？ 』 那么建议你看下这个回答 [(Why do pthreads’ condition variable functions require a mutex?
)](https://stackoverflow.com/questions/2763714/why-do-pthreads-condition-variable-functions-require-a-mutex)  
  
> The mutex is used to protect the condition variable itself. That's why you need it locked before you do a wait.  
  
既然如此那完全可以封装下嘛  
  
```cpp
using Lock = std::unique_lock<std::mutex>;  

class Semaphore
{
public:
    Semaphore(int count) noexcept
    : m_count(count) {}
 
    void post() noexcept
    {
        {
            Lock lock(m_mtx);
            ++m_count;
        }
        m_cv.notify_one();
    }
 
    void wait() noexcept
    {
        Lock lock(m_mtx);
        m_cv.wait(lock, []{ return m_count != 0; });
        --m_count;
    }
 
private:
    int m_count;
    std::mutex m_mtx;
    std::condition_variable m_cv;
};  

```
  
c++11 没有提供 semaphore，Boost.Thread 也没有提供，对此 Boost 是这样解释的 参考 [Why has class semaphore disappeared?](https://www.boost.org/doc/libs/1_31_0/libs/thread/doc/faq.html#question10)  
  
> Semaphore was removed as too error prone. The same effect can be achieved with greater safety by the combination of a mutex and a condition variable.  
  
通过组合 mutex 和 condition variable 可以达到相同的效果，且更加安全。  
  
那么对于 semaphore 的实现还有没有优化的空间呢？  
  
当然有了。必须有。而且是 C++11 自身的特性。这里使用到的是 new C++ memory model 中的 「atomic variable」和 「memory fences」。关于 C++11 的 「memory_model」有疑问的话可以看看这个回答 [C++11 introduced a standardized memory model](https://stackoverflow.com/questions/6319146/c11-introduced-a-standardized-memory-model-what-does-it-mean-and-how-is-it-g)
  
```cpp  
class FastSemaphore
{
public:
    FastSemaphore(int count) noexcept
    : m_count(count), m_semaphore(0) {}
 
    void post()
    {
        std::atomic_thread_fence(std::memory_order_release);
        int count = m_count.fetch_add(1, std::memory_order_relaxed);
        if (count < 0)
            m_semaphore.post();
    }
 
    void wait()
    {
        int count = m_count.fetch_sub(1, std::memory_order_relaxed);
        if (count < 1)
            m_semaphore.wait();
        std::atomic_thread_fence(std::memory_order_acquire);
    }
 
private:
    std::atomic<int> m_count;
    Semaphore m_semaphore;
};


```  
  
这里加了 release-acquire 的 「memory fence」 可以保证在 release-fence 前对于『同一个atomic』的 store 操作一定能被 acquire-fence 后 load。  
  
对于 「memory fense」有疑问的可以参考 [memory-barrier](https://mhy12345.xyz/translation/memory-barrier/) 和 [fences-as-memory-barriers](https://www.bilibili.com/video/av34387097?from=search&seid=12241519436904048925)
  
  
这里还可以坐下简化处理  
  
```cpp  
class FastSemaphore
{
public:
    FastSemaphore(int count) noexcept
    : m_count(count), m_semaphore(0) {}
 
    void post()
	{
	    int count = m_count.fetch_add(1, std::memory_order_release);
	    if (count < 0)
	        m_semaphore.post();
	}
	 
	void wait()
	{
	    int count = m_count.fetch_sub(1, std::memory_order_acquire);
	    if (count < 1)
	        m_semaphore.wait();
	}
 
private:
    std::atomic<int> m_count;
    Semaphore m_semaphore;
};


```  
  
关于 condition_variable 与 mutex 的『封装』到这里就已经完成了。至于如何实现 blocking queue 来替换目前的原始 queue，下篇会给出详细的实现。  
  
『试着优雅，尽管很难。』  
  
---
  By 唐瑞甫  
  2019-09-08

