---
layout:     post  
title:      听说线程池跟阻塞队列很配哦~  
subtitle:   摩托换宝马   
date:       2019-09-20  
author:     唐瑞甫  
header-img: img/post-bg-coffee.jpeg  
catalog: true  
tags:  
    - c++  

---  

[上篇文章](https://ruifutang.github.io/2019/09/08/%E7%BA%BF%E7%A8%8B%E6%B1%A0/)中我提到了一个优化点，就是可以用 「blocking queue」来替换原始的 queue，相当于把同步原语下沉到基础数据结构中，这样整体逻辑更简洁，耦合性也会更低。  
  
其实可以把线程池的使用场景看作是 「producer-consumer」模式下的一种应用，并且是 multi-producer-consumer 。当队列为空时，我们将消费者阻塞。当队列满载时，我们将生产者阻塞。『多个线程之间，我们利用 semephore 进行同步』。  
  
我选用了最原始来数组来进行存储，为了更细粒度的管理队列，分别记录 push 和 pop 操作各自的 index，当然还包括目前队列中正在使用的数量 count。根据上文中提到的，我需要对于 empty 跟 full 这两类事件进行有效的管理，所以我采用了两个 semephore 分别进行事件的响应与处理。  
  
```cpp  
#ifndef BLOCKING_QUEUE_H
#define BLOCKING_QUEUE_H

#include <mutex>
#include <atomic>
#include <utility>
#include <type_traits>
#include "fast_semaphore.h"
 
template<typename T>
class BlockingQueue
{
public:
	explicit BlockingQueue(unsigned int size)
	: m_size(size), m_pushIndex(0), m_popIndex(0), m_count(0),
	m_data((T*)operator new(size * sizeof(T))),
	m_emptySlots(size), m_fullSlots(0) {}
 
	BlockingQueue(const BlockingQueue&) = delete;
	BlockingQueue(BlockingQueue&&) = delete;
	BlockingQueue& operator = (const BlockingQueue&) = delete;
	BlockingQueue& operator = (BlockingQueue&&) = delete;
 
	~BlockingQueue() noexcept
	{
		while (m_count--)
		{
			m_data[m_popIndex].~T();
			m_popIndex = ++m_popIndex % m_size;
		}
		operator delete(m_data);
	}
 
	void push(const T& item)
	{
		m_emptySlots.wait();
		{
			Lock lock(m_mtx);
			try
			{
				new (m_data + m_pushIndex) T (item);
			}
			catch(...)
			{
				m_emptySlots.post();
				throw;
			}
			m_pushIndex = ++m_pushIndex % m_size;
            ++m_count;
		}
		m_fullSlots.post();
	}
 
	void pop(T& item) noexcept
	{
		m_fullSlots.wait();
		{
			Lock lock(m_mtx);
			item = m_data[m_popIndex];
			m_data[m_popIndex].~T();
			m_popIndex = ++m_popIndex % m_size;
            --m_count;
		}
		m_emptySlots.post();
	}
 
    bool empty()
    {
        Lock lock(m_mtx);
        return m_count == 0;
    }
 
private:
	const unsigned int m_size;
	unsigned int m_pushIndex;
	unsigned int m_popIndex;
	unsigned int m_count;
	T* m_data;
 
 	FastSemaphore m_emptySlots;
	FastSemaphore m_fullSlots;
	std::mutex m_mtx;
};  
  
#endif  

```
  
这里 push 跟 pop 操作都进行了加锁，目的是为了保证多个线程同时进行操作时 index 的正确性。这里可以同样借助于 fast_semaphore 中的思想，充分利用 「memory order」来进行无锁化的数据结构设计。而且这里加锁临界区其实只有 index 这一个变量需要保护，所以自然很适合用 「CAS」原语来进行改造。  
    
```c++
void push(const T& item) 
{
	m_emptySlots.wait();

	auto pushIndex = m_pushIndex.fetch_add(1, std::memory_order_relaxed);
	try
	{
		new (m_data + (pushIndex % m_size)) T (std::move(item));
	}
	catch(...)
	{
		m_emptySlots.post();
		throw;
	}
	
	++m_count;

	auto expected = m_pushIndex.load();
	while(!m_pushIndex.compare_exchange_strong(expected, m_pushIndex % m_size))
	{
		expected = m_pushIndex.load();
    }

	m_fullSlots.post();
}

void pop(T& item) noexcept
{
	m_fullSlots.wait();

	auto popIndex = m_popIndex.fetch_add(1, std::memory_order_relaxed);
	item = m_data[popIndex % m_size];
	m_data[popIndex % m_size].~T();
	--m_count;

	auto expected = m_popIndex.load();
	while(!m_popIndex.compare_exchange_strong(expected, m_popIndex % m_size))
    {
		expected = m_popIndex.load();
    }
	
	m_emptySlots.post();
}  

```
  
这里我选用的 「memory order」 是 memory\_order\_relaxed，我在自己的开发机上做过简单的测试，相对于默认的 memory\_order\_seq\_cst ，耗时可以降低 10% 左右。  
  
以下就是经过优化完以后的 「better」 版本。
  
```cpp  
#include <vector>
#include <thread>
#include <memory>
#include <future>
#include <functional>
#include <type_traits>
#include "queue.h"

class ThreadPool
{
public:
    ThreadPool(
        unsigned int capacity = std::thread::hardware_concurrency(),
        unsigned int threads = std::thread::hardware_concurrency())
    : m_tasks(capacity)
    {
        for(size_t i = 0; i < threads; ++i)
            m_threads.emplace_back(std::thread(
				[this]
				{
					for(;;)
					{
						auto workItem = m_tasks.pop();
						if(workItem == nullptr)
						{
							m_tasks.push(nullptr);
							break;
						}
						workItem();
					}
				}
            ));
    }
 
    ~ThreadPool() noexcept
    {
        m_tasks.push(nullptr);
        for(auto& thread : m_threads)
		{
            thread.join();
		}
    }
 
 
    template<typename F, typename... Args>
    auto enqueue(F&& f, Args&&... args) -> std::future<typename std::result_of<F(Args...)>::type>
    {
        using return_type = typename std::result_of<F(Args...)>::type;
        auto task = std::make_shared<std::packaged_task<return_type()>>(std::bind(std::forward<F>(f), std::forward<Args>(args)...));
        std::future<return_type> res = task->get_future();
        m_tasks.push([task](){ (*task)(); });
        return res;
    }
	
private:
    using ThreadVec = std::vector<std::thread>;
    ThreadVec m_threads;
	
	using Func = std::function<void(void)>;
    BlockingQueue<Func> m_tasks;
};

#endif  
```  
  
相对于最原始的版本，已经将同步原语全部做了封装，这样整体结构更简洁更清晰。这里采用了 nullptr 来替换了之前的 ready 变量，换了一种形式来实现 「clean」的操作，当线程 pop 取到的是 nullptr 时，**将其放回队列**，并且自身退出。这样可以保证目前系统中未处理的任务可以被处理完成以后整个线程池才被销毁。


  
『你能从一片空白里，看到可能吗？』  
  
---
  By 唐瑞甫  
  2019-09-08

