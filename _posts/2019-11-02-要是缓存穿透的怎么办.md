---
layout:     post  
title:      如何处理缓存穿透的问题？    
subtitle:   Bloom 后面还有个 Filter  
date:       2019-11-02  
author:     唐瑞甫  
header-img: img/post-bg-coffee.jpeg  
catalog: true  
tags:  
    - cache  
    - redis

---  

这篇文章主要聊一下缓存相关的问题。  
  
大规模的分布式系统内，缓存几乎是必备的组件之一，而且重要性不言而喻。如果缓存出现问题，则意味了 DB 也要受到威胁。  
  
为什么需要缓存？「快」。  
  
![天下武功，唯快不破](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1571768873876&di=3c40f5b7fb420bd525ee7193ee6b4d8e&imgtype=0&src=http%3A%2F%2Fimage.bitautoimg.com%2Fappimage%2Fmedia%2F20171101%2Fw1280_h720_f0607eaab75a4b80ad9c6a0e417f9029.jpeg)  
  
将频繁需要被访问的资源缓存在「内存」中，既可以提高请求的响应速度，又能够有效降低 DB 的负载。要做到这两点，就必须保证缓存的高命中率。一般来说，系统的核心缓存的命中率要保持在 99% 以上，非核心缓存的命中率也要尽量保证在 90%。如果缓存的命中率较低的话，大量的请求就会穿透到 DB 导致请求堵塞甚至拖垮整个系统。
  
低命中率则意味着会出现大量的「缓存穿透」，当然高命中率也会出现同样的现象。只不过高命中率下，少量请求穿透到 DB，相当于是微微细雨，而低命中率下，大量请求则就是洪水泛滥了。好的算法跟策略可以提高缓存的命中率，但并不意味着一定有效。在面对大量恶意请求攻击的情况下，如何保证缓存系统依然能够稳定高效的工作，则是本文需要探讨的主题。
  
  
### 缓存穿透  
  
![](https://pic2.zhimg.com/80/v2-715a05aead2fd8f3ea0e9246b7054ced_hd.jpg)
  
一个很常见的场景是请求首先读取缓存，如果读取失败或者没有读到，则读取 DB。如果这里是恶意请求查询数据库中不存在的数据的话，那么按照这个模式请求就一定会达到 DB，出现缓存穿透的现象。  
  
网上有很多文章会提到一个解决方案「回种空值」，也就是说当查询 DB 结果为空或者查询 DB 失败的情况下，向缓存中回种一个空值。这样当请求再次过来的时候，就可以避免出现穿透的情况。  
  
但是这个方案在实际中并不实用。因为现实中攻击者往往不会只使用固定的值，而是会伪造一大批请求过来查询不可能存在的用户，不可能存在的商品等，这时如果对于每个不存在的 key 值都回种一个空的 value 的话，则缓存内就会有大量的空值缓存，浪费内存空间。即使给这些空值缓存设置很短的过期时间，如果短时间内有大量这种恶意请求过来的话，就可能会导致缓存空间被占满，正常的缓存信息被剔除造成缓存命中率的下降。  
  
如果请求量比较大的情况下，应该评估下是否应该引入 「Bloom Filter」

### Bloom Filter  
  
[Bloom Filter](https://en.wikipedia.org/wiki/Bloom_filter) 本质上是有一个 bit array 和一个或一组 hash function 组成  
  
![Bloom Filter](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=1331317599,3665711911&fm=26&gp=0.jpg)  
  
可以看到 Bloom Filter 无论写入还是读取，都只需要一次寻址，所以性能非常好，时间复杂度都是 O(1)。在空间上，由于使用的是 bit 数组，所以相对于其他存储也有更高的利用率。如果我们需要保存 10 亿用户的数据，在不考虑冲突的理想情况下，需要的空间是 1000000000/8/1024/1024 = 119M 的空间，当然现实中使用的话为了降低冲突会将实际内存设置的更好一些，这个后面会单独提到。  
  
Bloom Filter 使用起来也非常简单，有很多开源的库已经实现了，所以就不需要再重复造轮子了。比如 Google guava 库  
  
```java
BloomFilter<Integer> filter = BloomFilter.create(
  Funnels.integerFunnel(),
  10000,
  0.07);
```  
  
以上都是介绍了 Bloom Filter 的优势，那么其对应的劣势又是什么呢？我觉得有以下 3 点：  
  
第一，使用 Bloom Filter 相当于引入了一个第三方的组件，会增加整个流程的复杂性。比如现在我们需要判断用户 ID 是否是已经注册过的 ID，需要 Bloom Filter 来过滤掉恶意的请求，那么在用户注册的流程中，就需要将用户的信息也保存到 Bloom Filter 里面。  
  
这里就会引入一个新的问题：Bloom Filter 如何存储？一个不错的方案是将 Bloom Filter 存放在 Redis 这类缓存中间件中间，这样既不会给整个业务流程带来太大额外的开销，又能保证 Bloom Filter 中的数据可以可靠的进行持久化。  
   
第二，使用 Bloom Filter 会存在一定的误判。不过 Bloom Filter 误判有一个特点，就是它只会出现 「false positive」的情况。也就是说当 Bloom Filter 判断元素存在时，它可能不存在。而**判断这个元素不存在时，它一定不存在**。  

这一点非常适合解决缓存穿透的问题。举个例子，现在有大量恶意请求查询未注册的用户信息，这时候 Bloom Filter 判断这些用户都没有注册过，如果我们不确定它是不是真的没有注册过，那么就还是需要去数据库和缓存中查询，这就使 Bloom Filter 失去了价值。  
我们也可以采用一些方案来减少 Bloom Filter 误判的概率。比如可以增大数组的容量，使用多个不同的 hash 函数来进行计算，根据业务特性设计出更适合的 hash 函数等。  
  
第三，Bloom Filter 不支持删除元素。这个其实得分场景，如果是针对用户来过滤，那么完全不成问题，因为几乎不会有删除用户信息的情况。而如果是针对商品的话，那就会有一点麻烦了，毕竟商品是不断更新的。  
  
这个问题其实也可以解决，比如将 Bloom Filter 中的 bit 数组替换成 int 型数组，然后数组的中保存元素出现的次数，那么当出现 hash 冲突的时候直接将数字累加就可以了。这样当需要删除元素的时候，就可以将 Bloom Filter 对应位置上的值进行递减操作，这样就可以让 Bloom Filter 支持删除操作。  
  
#### 热点 KEY
  
Bloom Filter 虽然可以一定程度上解决缓存穿透的问题，但是却无法解决「dog-pile effect」。比如缓存中现在有一个热点key，它一旦失效会有大量请求穿透到 DB，瞬间对 DB 造成极大的压力甚至拖垮 DB。  
  
Bloom Filter 显然没法解决这类问题，后面我会单独写一篇文章来讨论如何解决热点 key 失效所引发的瞬时洪泛问题。


 
---
  By 唐瑞甫  
  2019-11-02

